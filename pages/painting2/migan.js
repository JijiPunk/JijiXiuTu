global.wasm_url = '/utils/opencv3.4.16.wasm.br'
// opencv_exec.js‰ºö‰ªéglobal.wasm_urlËé∑ÂèñwasmË∑ØÂæÑ
let cv = require('../../utils/opencv_exec.js');

export class Migan {

  // net inference session
  session;
  // is ready
  ready;
  speedTime = 0.0;
  res = 512;
  padding = 128;
  debugMode = true;
  has_migan = false;

  constructor() {
    this.ready = false;
  }

  // Âä†ËΩΩÊ®°Âûã
  async load(forcedLoad) {
    const modelPath = `${wx.env.USER_DATA_PATH}/migan.onnx`;
    console.log(modelPath);
  
    try {
      if (forcedLoad) {
        await this.forcedLoad();
      } else {
        // Âà§Êñ≠‰πãÂâçÊòØÂê¶Â∑≤Áªè‰∏ãËΩΩËøáonnxÊ®°Âûã
        try {
          wx.getFileSystemManager().accessSync(modelPath);
          console.log("File already exists at: " + modelPath);
          const stats = wx.getFileSystemManager().statSync(modelPath);
          console.log("File size: " + stats.size + " bytes");
          this.has_migan = true;
        } catch (error) {
          console.error(error);
          await this.forcedLoad();
        }
      }
    } catch (error) {
      throw error;
    }
    // ÂàõÂª∫Êé®Êñ≠‰ºöËØù
    await this.createInferenceSession(modelPath, forcedLoad);
    console.log("start resolve: ", this.has_migan);
    return this.has_migan;
  }

  forcedLoad() {
    return new Promise((resolve, reject) => {
      const modelPath = `${wx.env.USER_DATA_PATH}/migan.onnx`;
      wx.chooseMessageFile({
        count: 1,
        type: 'file',
        extension: ['onnx', 'ONNX'],
        success: (res) => {
          console.log('res:', res)
          // tempFilePathÂèØ‰ª•‰Ωú‰∏∫imgÊ†áÁ≠æÁöÑsrcÂ±ûÊÄßÊòæÁ§∫ÂõæÁâá
          const tempFilePath = res.tempFiles[0].path;
          // ‰øùÂ≠òÊ®°ÂûãÂà∞Êú¨Âú∞
          wx.getFileSystemManager().saveFile({
            tempFilePath: tempFilePath,
            filePath: modelPath,
            success: () => { // Êñá‰ª∂ÊàêÂäü‰øùÂ≠òÂêé              
              this.has_migan = true;
              console.log("Saved onnx model at path: " + modelPath);
              wx.showToast({
                title: 'ÂºÄÂßãÂä†ËΩΩÊ®°Âûã',
                icon: 'loading',
                duration: 2000
              })
              resolve(); // resolve promise after file check successful
            },
            
            fail: (error) => { // ‰øùÂ≠òÊñá‰ª∂Â§±Ë¥•Êó∂
              console.log("Failed to save file: " + modelPath);
              reject(error); // reject the promise if save file failed
            }
          });
        },
        fail: (error) => { // ÈÄâÊã©Êñá‰ª∂Â§±Ë¥•Êó∂
          console.log("Failed to choose file");
          reject(error); // reject the promise if choose file failed
        },
      })
    });
  }

// ÂàõÂª∫Êé®Êñ≠‰ºöËØù
createInferenceSession(modelPath, forcedLoad) {
  return new Promise((resolve, reject) => {
    try {
      this.session = wx.createInferenceSession({
        model: modelPath,
        precisionLevel: 4,
        allowNPU: false,
        allowQuantize: false,
      });

      // ËÆæÁΩÆÈîôËØØÂ§ÑÁêÜ
      this.session.onError((error) => {
        console.error(error);
        wx.showToast({
          title: 'Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•',
          icon: 'error',
          duration: 2000
        })
        reject(error);  // Â¶ÇÊûúÂèëÁîüÈîôËØØÔºåÊàë‰ª¨ reject Ëøô‰∏™ promise
      });

      // Á≠âÂæÖ‰ºöËØùÂä†ËΩΩÂÆåÊàê
      this.session.onLoad(() => {
        this.ready = true;
        console.log("load ok");
        if(forcedLoad){
          wx.showToast({
            title: 'Ê®°ÂûãÂä†ËΩΩÊàêÂäü',
            icon: 'success',
            duration: 2000
          })
        }
        resolve();  // Ê®°ÂûãÂä†ËΩΩÊàêÂäüÊó∂ÔºåÊàë‰ª¨ resolve Ëøô‰∏™ promise
      });

    } catch (error) {
      // Â§ÑÁêÜÂú®ËøáÁ®ã‰∏≠ÂèØËÉΩÂèëÁîüÁöÑ‰ªª‰ΩïÈîôËØØ
      console.error('ÂàõÂª∫Êé®Êñ≠‰ºöËØùÊó∂Âá∫ÈîôÔºö');
      reject(error);  // Â¶ÇÊûúÂú®ÊñπÊ≥ï‰Ωì‰∏≠ÂèëÁîüÂºÇÂ∏∏ÔºåÊàë‰ª¨ reject Ëøô‰∏™ promise
    }
  });
}


  async downloadFile(url, onCall = () => {}) {
    if (!url) {
      throw new Error('Invalid url');
    }

    return new Promise((resolve, reject) => {
      const downloadTask = wx.downloadFile({
        url: url,
        success: res => {
          if (res.statusCode === 200) {
            if (res.totalBytesExpectedToWrite === res.totalBytesWritten) {
              setTimeout(function () {
                wx.hideLoading()
              }, 200)
              wx.showToast({
                title: 'Ê®°Âûã‰∏ãËΩΩÊàêÂäü',
                icon: 'success',
                duration: 3000
              })
              resolve(res);
            }

          } else {
            console.error(`Download failed with status code: ${res.statusCode}`);
          }
        },
        fail: err => {},
      });

      downloadTask.onProgressUpdate(res => {
        if (res.totalBytesExpectedToWrite === res.totalBytesWritten) {
          setTimeout(function () {
            wx.hideLoading()
          }, 200)
        } else {
          wx.showLoading({
            title: '‰∏ãËΩΩËøõÂ∫¶ ' + res.progress,
          })
        }

        if (onCall(res) === false) {
          downloadTask.abort();
          reject(new Error('Download aborted by onCall'));
        }
      });
    });
  }

  async execute(image, mask, src) {
    this.showDebugLog(" - the image is processing");
    wx.showLoading({      
      title: 'üçµ Ê≠£Âú®Ë∞ÉÁî®Ê®°Âûã‰øÆÂõæ',
    })
    // Ëé∑ÂèñË£ÅÂâ™ËæπÁïåÊ°ÜÂùêÊ†á
    const [x_min, x_max, y_min, y_max] = this.getMaskedBbox(mask);

    // Ë£ÅÂâ™ÂõæÂÉèÂíå mask
    const croppedImg = image.roi(new cv.Rect(x_min, y_min, x_max - x_min, y_max - y_min));
    const croppedMask = mask.roi(new cv.Rect(x_min, y_min, x_max - x_min, y_max - y_min));

    // È¢ÑÂ§ÑÁêÜ
    const modelInput = this.preprocess(croppedImg, croppedMask);
    this.showDebugLog(" - preprocess is completed");

    //*
    // Ê®°ÂûãÊé®ÁêÜ
    const modelOutput = await this.runSession(modelInput);
    this.showDebugLog(" - model inference is completed");

    // ÂêéÂ§ÑÁêÜ
    const postResult = await this.postprocess(croppedImg, croppedMask, modelOutput);
    this.showDebugLog(" - postprocess is completed");
    croppedImg.delete();
    croppedMask.delete();

    // Êõ¥Êñ∞ÂéüÂßãÂõæÂÉè
    const imageResult = src.clone();
    postResult.copyTo(imageResult.roi(new cv.Rect(x_min, y_min, x_max - x_min, y_max - y_min)));
    postResult.delete();

    this.showDebugLog(" - the converted image is generated");
    setTimeout(function () {
      wx.hideLoading()
    }, 200)

    return imageResult;
    //*/
    /* for test without phone.
    const src_rgba = new cv.Mat();
     cv.cvtColor(image, src_rgba, cv.COLOR_RGB2RGBA);
    return new Uint8ClampedArray(src_rgba.data);
    */
  }

  async runSession(modelInput) {
    const xinput = {
      shape: [1, 4, 512, 512],
      data: modelInput.buffer,
      type: 'float32',
    };

    return new Promise((resolve, reject) => {
      try {
        this.session.run({
          input: xinput
        }).then(res => {
          let output = new Float32Array(res.output.data);
          resolve(output);
        }).catch((err) => {
          console.log(err);
          reject(err);
        });
      } catch (error) {
        wx.showToast({
          title: 'ËøêË°åÂ§±Ë¥•',
          icon: 'error',
          duration: 2000
        });
        setTimeout(function () {
          wx.hideLoading();
        }, 200);
        reject(error);
      }
    });
  }

  getMaskedBbox(mask) {
    // Convert the input mask to a binary image
    const tempMask = new cv.Mat();
    cv.bitwise_not(mask, tempMask);
    const binaryMask = new cv.Mat();
    cv.threshold(tempMask, binaryMask, 254, 255, cv.THRESH_BINARY);

    // Find contours in the binary mask
    const contours = new cv.MatVector();
    const hierarchy = new cv.Mat();
    cv.findContours(binaryMask, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

    // Find the bounding box of the contours
    let xMin = Number.MAX_VALUE;
    let xMax = Number.MIN_VALUE;
    let yMin = Number.MAX_VALUE;
    let yMax = Number.MIN_VALUE;

    for (let i = 0; i < contours.size(); ++i) {
      const rect = cv.boundingRect(contours.get(i));
      xMin = Math.min(xMin, rect.x);
      xMax = Math.max(xMax, rect.x + rect.width);
      yMin = Math.min(yMin, rect.y);
      yMax = Math.max(yMax, rect.y + rect.height);
    }

    // Apply padding
    xMin = Math.max(xMin - this.padding, 0);
    xMax = Math.min(xMax + this.padding, mask.cols);
    yMin = Math.max(yMin - this.padding, 0);
    yMax = Math.min(yMax + this.padding, mask.rows);

    // Apply resolution constraint
    const cropSize = Math.max(xMax - xMin, yMax - yMin, this.res);

    // Calculate center and offset
    const cntX = Math.floor((xMin + xMax) / 2);
    const cntY = Math.floor((yMin + yMax) / 2);
    const offset = Math.floor(cropSize / 2);

    // Apply offset constraints
    xMin = Math.max(cntX - offset, 0);
    xMax = Math.min(cntX + offset, mask.cols);
    yMin = Math.max(cntY - offset, 0);
    yMax = Math.min(cntY + offset, mask.rows);

    // Clean up
    tempMask.delete();
    binaryMask.delete();
    contours.delete();
    hierarchy.delete();

    return [xMin, xMax, yMin, yMax];
  }

  preprocess(image, mask) {
    const dsize = new cv.Size(this.res, this.res); // Êñ∞Â∞∫ÂØ∏

    // Resize image using BILINEAR interpolation
    const resizedImage = new cv.Mat();
    cv.resize(image, resizedImage, dsize, 0, 0, cv.INTER_LINEAR);

    // Resize mask using NEAREST interpolation
    const resizedMask = new cv.Mat();
    cv.resize(mask, resizedMask, dsize, 0, 0, cv.INTER_NEAREST);

    // Convert image and mask to float32
    const imageChwArray = this.convertImgToChwArray(resizedImage);
    resizedImage.delete();
    const maskChwArray = this.convertMaskToChwArray(resizedMask);
    resizedMask.delete();

    const modelInput = this.mergeImgAndMask(imageChwArray, maskChwArray);

    return modelInput;
  }

  // model_input = torch.cat([mask - 0.5, image * mask], dim=1)
  mergeImgAndMask(img, mask) {
    const temp = new Float32Array(img.length)
    const maskTemp = new Float32Array(mask.length)
    const C = 3
    const H = this.res
    const W = this.res

    for (let c = 0; c < C; c++) {
      for (let h = 0; h < H; h++) {
        for (let w = 0; w < W; w++) {
          temp[c * H * W + h * W + w] =
            img[c * H * W + h * W + w] * mask[h * W + w]
        }
      }
    }

    for (let h = 0; h < H; h++) {
      for (let w = 0; w < W; w++) {
        maskTemp[h * W + w] = mask[h * W + w] - 0.5
      }
    }
    //ÈìæÊé•‰∏§‰∏™Â≠óËäÇÊï∞ÁªÑ
    const res = new Float32Array(mask.length + img.length)
    const maskLength = mask.length
    for (let c = 0; c < maskLength; c++) {
      res[c] = maskTemp[c]
    }

    const imgLength = img.length
    for (let c = 0; c < imgLength; c++) {
      res[maskLength + c] = temp[c]
    }

    return res

  }

  convertImgToChwArray(imgData) {
    const channels = new cv.MatVector();
    cv.split(imgData, channels); // ÂàÜÂâ≤ÈÄöÈÅì

    const C = channels.size(); // ÈÄöÈÅìÊï∞
    const H = imgData.rows; // ÂõæÂÉèÈ´òÂ∫¶
    const W = imgData.cols; // ÂõæÂÉèÂÆΩÂ∫¶

    const chwArray = new Float32Array(C * H * W); // ÂàõÂª∫Êñ∞ÁöÑÊï∞ÁªÑÊù•Â≠òÂÇ®ËΩ¨Êç¢ÂêéÁöÑÊï∞ÊçÆ

    for (let c = 0; c < C; c++) {
      const channelData = channels.get(c).data;
      for (let h = 0; h < H; h++) {
        for (let w = 0; w < W; w++) {
          chwArray[c * H * W + h * W + w] = (channelData[h * W + w] * 2) / 255 - 1;
        }
      }
    };
    return chwArray;
  }

  convertMaskToChwArray(imgData) {
    const channels = new cv.MatVector();
    cv.split(imgData, channels); // ÂàÜÂâ≤ÈÄöÈÅì

    const C = 1; // ÈÄöÈÅìÊï∞
    const H = imgData.rows; // ÂõæÂÉèÈ´òÂ∫¶
    const W = imgData.cols; // ÂõæÂÉèÂÆΩÂ∫¶

    const chwArray = new Float32Array(C * H * W); // ÂàõÂª∫Êñ∞ÁöÑÊï∞ÁªÑÊù•Â≠òÂÇ®ËΩ¨Êç¢ÂêéÁöÑÊï∞ÊçÆ

    for (let c = 0; c < C; c++) {
      const channelData = channels.get(c).data; // Ëé∑ÂèñÂçï‰∏™ÈÄöÈÅìÁöÑÊï∞ÊçÆ
      for (let h = 0; h < H; h++) {
        for (let w = 0; w < W; w++) {
          chwArray[c * H * W + h * W + w] = channelData[h * W + w] / 255;
        }
      }
    };
    return chwArray;
  }

  async postprocess(image, mask, modelOutput) {

    // deal with the modelOutput data and convert it into a CV_8UC3 Mat.
    const chwToHwcData = this.convertToHwcData(modelOutput);
    this.showDebugLog(" - postprogess: convertToHwcData is completed");

    const rgba = new Uint8ClampedArray(chwToHwcData);
    const outImgMat = cv.matFromArray(this.res, this.res, cv.CV_8UC4, rgba);

    // Resize model output using BILINEAR interpolation
    const dsize = new cv.Size(image.cols, image.rows);
    cv.resize(outImgMat, outImgMat, dsize, 0, 0, cv.INTER_LINEAR);
    //await this.tempSaveImageFile(outImgMat);

    // deal with the mask data: apply max pooling
    const maskTemp = this.maxPool2D(mask);
    this.showDebugLog(" - postprogess: maxPool is completed");

    // deal with the mask data: apply Gaussian blur to the mask
    const maskBlur = this.gaussianSmoothing(maskTemp);
    this.showDebugLog(" - postprogess: gaussianSmoothing is completed");
    maskTemp.delete();

    // Compose the final image
    const composedImg = this.createComposedImage(image, maskBlur, outImgMat);
    maskBlur.delete();
    outImgMat.delete();
    this.showDebugLog(" - postprogess: createComposedImage is completed");

    return composedImg;
  }

  createComposedImage(image, mask, modelOutput) {
    const imageRgba = new cv.Mat();
    cv.cvtColor(image, imageRgba, cv.COLOR_RGB2RGBA);

   /*
    const outputArray = new Uint8ClampedArray(modelOutput.data);
    const maskDataLength = mask.data.length;
    for (let i = 0; i < maskDataLength; i++) {
      if (mask.data[i] !==255 && mask.data[i] !==0) {
        const realMark = mask.data[i]/255;
        const realIndex = 4 * i;
        outputArray[realIndex] = imageRgba.data[realIndex] * realMark + modelOutput.data[realIndex] * (1 - realMark);
        outputArray[realIndex + 1] = imageRgba.data[realIndex + 1] * realMark + modelOutput.data[realIndex + 1] * (1 - realMark);
        outputArray[realIndex + 2] = imageRgba.data[realIndex + 2] * realMark + modelOutput.data[realIndex + 2] * (1 - realMark);
      }
    };
    const newOutput = cv.matFromArray(modelOutput.rows, modelOutput.cols, cv.CV_8UC4, outputArray);
    */
    cv.bitwise_not(mask, mask);
    modelOutput.copyTo(imageRgba, mask);
    //newOutput.copyTo(imageRgba, mask);
    //newOutput.delete();

    return imageRgba;
  }

  convertToHwcData(modelOutput) {
    const chwToHwcData = [];
    const width = this.res;
    const height = this.res;
    const size = width * height;
    const channels = 3;

    for (let h = 0; h < height; h++) {
      for (let w = 0; w < width; w++) {
        for (let c = 0; c < channels; c++) {
          // RGBÈÄöÈÅì
          const chwIndex = c * size + h * width + w;
          const pixelVal = modelOutput[chwIndex] * 0.5 + 0.5;
          let newPiex = pixelVal;
          if (pixelVal > 1) {
            newPiex = 1;
          } else if (pixelVal < 0) {
            newPiex = 0;
          }
          chwToHwcData.push(newPiex * 255); // ÂΩí‰∏ÄÂåñÂèçËΩ¨
        }
        chwToHwcData.push(255) // AlphaÈÄöÈÅì
      }
    };
    return chwToHwcData;
  }

  maxPool2D(src) {
    let kernel = new cv.Mat.ones(5, 5, cv.CV_8U);
    // ËÜ®ËÉÄÊìç‰Ωú
    let dst = new cv.Mat();
    cv.dilate(src, dst, kernel, new cv.Point(-1, -1), 1, cv.BORDER_CONSTANT, cv.morphologyDefaultBorderValue());
    return dst;
  }

  minPool2D(src) {
    let kernel = new cv.Mat.ones(5, 5, cv.CV_8U);
    // ËÜ®ËÉÄÊìç‰Ωú
    let dst = new cv.Mat();
    cv.erode(src, dst, kernel, new cv.Point(-1, -1), 1, cv.BORDER_CONSTANT, cv.morphologyDefaultBorderValue());
    return dst;
  }

  gaussianSmoothing(inputMat) {
    let channels = 1; // ËÆæÁΩÆ‰∏∫ÂõæÂÉèÁöÑÈÄöÈÅìÊï∞
    const kernelSize = 5; // ËÆæÁΩÆÂç∑ÁßØÊ†∏ÁöÑÂ§ßÂ∞è
    const sigma = 1.5; // ËÆæÁΩÆÈ´òÊñØÂáΩÊï∞ÁöÑÊ†áÂáÜÂ∑Æ
    const dim = 2; // ËÆæÁΩÆÂç∑ÁßØÊ†∏ÁöÑÁª¥Â∫¶

    // Á°Æ‰øù channels ‰∏çË∂ÖËøáËæìÂÖ•ÂõæÂÉèÁöÑÈÄöÈÅìÊï∞
    channels = 1;
    // ÂàõÂª∫ËæìÂá∫Áü©Èòµ
    const outputMat = new cv.Mat();
    // ÊâßË°å Gaussian Smoothing
    cv.GaussianBlur(inputMat, outputMat, new cv.Size(kernelSize, kernelSize), sigma, sigma, cv.BORDER_DEFAULT);

    return outputMat;
  }

  isReady() {
    return this.ready;
  }

  getTime() {
    return this.speedTime;
  }

  dispose() {
    this.session.destroy();
  }

  showDebugLog(logMessage) {
    if (this.debugMode) {
      const currentTime = new Date();
      const formattedTime = currentTime.toISOString().slice(0, 23).replace("T", " "); // Ëé∑ÂèñÊó∂Èó¥Êà≥Â≠óÁ¨¶‰∏≤ÔºåÊ†ºÂºè‰∏∫YYYY-MM-DD HH:mm:ss
      console.log(formattedTime + logMessage);
    }
  }

  async tempSaveImageFile(image) {
    const base64Img = this.imageDataToDataURL(image);
    const number = Math.random();
    wx.getFileSystemManager().writeFile({
      filePath: wx.env.USER_DATA_PATH + '/pic_inpaint' + number + '.jpg',
      data: base64Img.replace(/^data:image\/\w+;base64,/, ""),
      encoding: 'base64',
      success: async (res) => {
        try {
          await wx.saveImageToPhotosAlbum({
            filePath: wx.env.USER_DATA_PATH + '/pic_inpaint' + number + '.jpg',
            success(res) {
              wx.showToast({
                title: 'ÂàÜ‰∫´ÂõæÂ∑≤ÊàêÂäü‰øùÂ≠òÂà∞Áõ∏ÂÜå',
                icon: 'none'
              });
            },
            fail(res) {
              wx.showToast({
                title: 'ÁîüÊàêÂàÜ‰∫´ÂõæÂ§±Ë¥•ÔºåËØ∑ÈáçËØï',
                icon: 'none'
              });
            }
          });
        } catch (error) {
          wx.showToast({
            title: 'ËØ∑ÊéàÊùÉ‰øùÂ≠òÂõæÁâáÊùÉÈôê‰ª•‰øùÂ≠òÂàÜ‰∫´Âõæ',
            icon: 'none'
          });
        }
      },
      fail: (err) => {
        console.log(err);
      }
    });
  }

  imageDataToDataURL(input) {
    const offscreenCanvas = wx.createOffscreenCanvas({
      type: '2d',
      width: input.cols,
      height: input.rows
    });
    cv.imshow(offscreenCanvas, input);
    return offscreenCanvas.toDataURL(('image/jpg', 0.9));
  }

}